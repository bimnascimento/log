input {
  # jdbc {
  #   jdbc_driver_library => "/logstash-6.3.0/lib/sqljdbc42.jar"
  #   jdbc_driver_class => "com.microsoft.sqlserver.jdbc.SQLServerDriver"
  #   jdbc_connection_string => "jdbc:sqlserver://XXX:XXX;databaseName=XXX"
  #   jdbc_user => "XXX"
  #   jdbc_password => "XXX"
  #   schedule => "* * * * *"
  #   statement => "select xxx from XXX"
  # }
  #  file {
  #     path => "/tmp/logs/rails/*.log"
  #     start_position => "beginning"
  #     type => "rails-logs"
  #  }
  #  file {
  #     path => "/tmp/logs/nginx/*.log"
  #     start_position => "beginning"
  #     type => "nginx-logs"
  #  }
  # file {
  #     path => "/tmp/logs/**/*.gz"
  #     tags => "bigdata-dev1"
  #     codec => "gzip_lines"
  #     start_position => "beginning"
  #     sincedb_path => "gzip"
  # }
  file {
      path => "/tmp/logs/**/*.log"
      start_position => "beginning"
      sincedb_path => "/dev/null"
      # type => "logType"
      # type => "file-logs"
      # sincedb_path => "/dev/null"
      # codec => "json"
      # codec => json_lines
      codec => multiline {
        pattern => "^%{TIMESTAMP_ISO8601} "
        negate => true
        what => "previous"
      }
   }
   gelf { 
      # type => 'gelf'
      port => 12203
   }
  #  syslog {
  #     codec => "json"
  #  }
}
filter {
  # grok {
  #   match => {"message" => ["%{TIMESTAMP_ISO8601:logdate} %{WORD:hostname} %{WORD:container_name}: %{GREEDYDATA:[@metadata][messageline]}",
  #   "%{TIMESTAMP_ISO8601:logdate} %{WORD:hostname} %{WORD:container}\[%{INT:haprorxy_id}\]: %{GREEDYDATA:[@metadata][messageline]}"]}
  # }
  # grok {
  #   # 2020-06-17 12:19:14.547 [DefaultMessageListenerContainer-3] INFO  [{}] b.c.b.n.p.m.l.InQueueListenerWMQ - Processing InQueueListenerWMQ [CurrentAccountMessage].
  #   # match => {"message" => ["%{TIMESTAMP_ISO8601:timestamp} \[%{GREEDYDATA:hostname}\] %{GREEDYDATA:loglevel} %{GREEDYDATA:[@metadata][messageline]} %{GREEDYDATA:message}"]}
  #   match => {"message" => ["(?m)%{TIMESTAMP_ISO8601:timestamp} \[%{GREEDYDATA:thread}\] %{GREEDYDATA:logLevel}  %{GREEDYDATA:[@metadata][messageline]} %{GREEDYDATA:class} \- %{GREEDYDATA:message}"]}
  #   overwrite => [ "message" ]
  #   break_on_match => false
  #   remove_tag => ["_grokparsefailure","multiline"]
  # }
  # multiline {
	# 	pattern => '(?m)%{TIMESTAMP_ISO8601:timestamp} \[%{GREEDYDATA:thread}\] %{GREEDYDATA:logLevel} '
	# 	negate => true
	# 	what => previous
	# }
  # mutate {
  #   remove_field => ["message", "@timestamp"]
  # }
  # json {
  #   source => "[@metadata][messageline]"
  # }
  # json { 
  #   source => "message" 
  # } 
  # date { 
  #   match => ["timestamp", "UNIX"]
  # }
  # if [type] == "rails-logs" {
  #   grok {
  #     match => {"message" => "[DFEWI], \[%{TIMESTAMP_ISO8601:occurrency_time} #%{POSINT:pid}\] %{LOGLEVEL:loglevel} -- : \[%{UUID:uuid}\] %{GREEDYDATA:message}"}
  #     overwrite => [ "message" ]
  #     remove_field => ["uuid"]
  #   }
  # }
  # if [type] == "nginx-logs" {
  #   grok {
  #     match => {"message" => "%{IPORHOST:clientip} - - \[%{HTTPDATE:timestamp}\] \"%{WORD:verb} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) (?:/\"(?:%{URI:referrer}|-)\"|%{QS:referrer}) %{QS:agent}"}
  #   }
  #   date {
  #     match => [ "timestamp", "dd/MMM/YYYY:H:m:s Z" ] 2020-06-17 16:22:58.998
  #   }
  # }
  # mutate {
  #  add_field => { "message" => "Test server" }
  #  add_field => { "host" => "localhost" }
  # }

  # 2020-06-17 12:19:14.547 [DefaultMessageListenerContainer-3] INFO  [{}] b.c.b.n.p.m.l.InQueueListenerWMQ - Processing InQueueListenerWMQ [CurrentAccountMessage].
  # multiline {
	# 	pattern => '^(?m)%{TIMESTAMP_ISO8601} \[%{DATA}\] %{LOGLEVEL} '
	# 	negate => true
	# 	what => previous
	# }
	# grok {
  #   # pattern => [ "(?m)\[%{TIMESTAMP_ISO8601:timestamp}\] \[%{HOSTNAME:host}\] \[%{DATA:thread}\] %{LOGLEVEL:logLevel} %{DATA:class}@%{DATA:method}:%{DATA:line} \- %{GREEDYDATA:message}"]
	# 	pattern => [ "%{TIMESTAMP_ISO8601:timestamp} \[%{DATA:thread}\] %{LOGLEVEL:logLevel} %{GREEDYDATA:[@metadata][messageline]} %{DATA:class}@%{DATA:method}:%{DATA:line} \- %{GREEDYDATA:message}"]		
	# 	overwrite => [ 
	# 	    "host", 
	# 	    "message" 
  #   ]
	# 	add_field => { 
	# 	    "code" => "%{class}@%{method}:%{line}"
  #   }
	# }
	# if "_grokparsefailure" in [tags] {
	# 	grok {
	# 		# match => ["message", "(?m)\[%{TIMESTAMP_ISO8601:timestamp}\] \[%{HOSTNAME:host}\] \[%{DATA:thread}\] %{LOGLEVEL:logLevel} %{DATA:class}@%{DATA:method}:%{DATA:line} \- (?<message>(.|\r|\n)*)" ]
	# 		match => ["message", "(?m)%{TIMESTAMP_ISO8601:timestamp} \[%{DATA:thread}\] %{LOGLEVEL:logLevel} %{GREEDYDATA:[@metadata][messageline]} %{DATA:class}@%{DATA:method}:%{DATA:line} \- (?<message>(.|\r|\n)*)" ]
	# 		overwrite => [ 
	# 		    "host",
	# 		    "message" 
	# 	  ]
	# 		add_field => { 
	# 		    "code" => "%{class}@%{method}:%{line}"
	# 	  }
	# 	}
	# }
  mutate {
    gsub => [ "message", "r", "" ]   
  }
  mutate {
    remove_field => ["kv-data", "_grokparsefailure"]
  }
  # mutate {
  #   gsub => [ "json" , "," ]
  # }
  # mutate {
  #   replace => { "json" => "[%{json}]" }
  # }
  grok {
    # match => [ "message", "(?m)%{TIMESTAMP_ISO8601:timestamp} \[%{GREEDYDATA:thread}\] %{GREEDYDATA:logLevel} %{GREEDYDATA:[@metadata][messageline]} %{DATA:class} \- %{GREEDYDATA:message}" ]
    match => [ "message", "(?m)%{TIMESTAMP_ISO8601:timestamp} \[%{DATA:thread}\] %{LOGLEVEL:logLevel} \[\{%{GREEDYDATA:kv-data}\}\] %{DATA:class} \- %{GREEDYDATA:message}" ]
    overwrite => [ "message" ]
    # skip_on_invalid_json => true
  }
  kv {
    allow_duplicate_values => "false"
    source => "kv-data" 
    # field_split_pattern => ", "
    field_split => ","
    value_split => "="
    trim_key => " "
    # include_brackets => "true"
    # recursive => "true"
    # remove_field => [ "kvpairs" ] # Delete the field afterwards
  }
	date {
		match => [ "timestamp" , "YYYY-MM-dd HH:mm:ss.SSS" ]
		target => "@timestamp"
	}
}
output {
  stdout { 
    codec => rubydebug { 
      # metadata => true
    }
  }
  # gelf {
  #   # id => "my_plugin_id"
  #   host => "localhost"
  #   port => 12201
  #   short_message => "Testing gelf output 12201"
  # }
  # gelf {
  #   # id => "my_plugin_id"
  #   host => "localhost"
  #   port => 12202
  #   short_message => "Testing gelf output 12202"
  # }
  gelf {
    id => "read_file"
    host => "graylog"
    port => 12202
  }
  # elasticsearch {
  #   hosts => ["elasticsearch"]
  #   # action => "index"
  #   # template_name => "logs_elk"
  #   # document_type => "applicationlogs"
  #   # index => "logstash-%{[type]}-%{+YYYY.MM.dd}"
  #   # user => "elastic"
	# 	# password => "changeme"
  # }
}